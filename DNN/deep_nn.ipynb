{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x7fd26023e1d0>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "### sigmoid DNN ###\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        self.linear3 = nn.Linear(H2, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.linear1(x))\n",
    "        x = torch.sigmoid(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "model = Net(25, 50, 50, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "### tanh DNN ###\n",
    "class NetTanh(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        super(NetTanh, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        self.linear3 = nn.Linear(H2, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.linear1(x))\n",
    "        x = torch.tanh(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('linear1.weight',\n              tensor([[ 0.5672, -0.1062],\n                      [ 0.0950, -0.7037],\n                      [-0.4370, -0.6238],\n                      [-0.3244, -0.3555],\n                      [-0.2603,  0.1897]])),\n             ('linear1.bias',\n              tensor([ 0.2265, -0.2988,  0.3972, -0.5336,  0.0151])),\n             ('linear2.weight',\n              tensor([[ 0.2002, -0.4043, -0.0483, -0.4221,  0.0464],\n                      [ 0.3649,  0.3876,  0.1515, -0.2125,  0.3433],\n                      [-0.4433,  0.2778, -0.2198,  0.2249,  0.0263],\n                      [-0.3574,  0.2918,  0.3817, -0.0623, -0.1894],\n                      [ 0.4068,  0.3609, -0.1206, -0.2718, -0.0192]])),\n             ('linear2.bias',\n              tensor([ 0.3456, -0.3081, -0.3023,  0.2690, -0.3898])),\n             ('linear3.weight',\n              tensor([[ 0.2579, -0.2733,  0.0681, -0.1431,  0.0789]])),\n             ('linear3.bias', tensor([-0.1783]))])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ReLu DNN ###\n",
    "class NetReLu(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        super(NetReLu, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        self.linear3 = nn.Linear(H2, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        x = torch.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "model = NetReLu(2, 5, 5, 1)\n",
    "model.state_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "NetReLu_add_Dropout(\n  (linear1): Linear(in_features=2, out_features=5, bias=True)\n  (linear2): Linear(in_features=5, out_features=5, bias=True)\n  (linear3): Linear(in_features=5, out_features=1, bias=True)\n  (drop): Dropout(p=0.5, inplace=False)\n)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Dropout ###\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NetReLu_add_Dropout(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out, p):\n",
    "        super(NetReLu_add_Dropout, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        self.linear3 = nn.Linear(H2, D_out)\n",
    "        self.drop = nn.Dropout(p=p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.drop(self.linear1(x)))\n",
    "        x = F.relu(self.drop(self.linear2(x)))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "model = NetReLu_add_Dropout(2, 5, 5, 1, p=0.5)\n",
    "model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "NetTanh_Xavier(\n  (linear1): Linear(in_features=2, out_features=5, bias=True)\n  (linear2): Linear(in_features=5, out_features=5, bias=True)\n  (linear3): Linear(in_features=5, out_features=1, bias=True)\n)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Xavier initialization ###\n",
    "class NetTanh_Xavier(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        super(NetTanh_Xavier, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        torch.nn.init.xavier_uniform_(self.linear1.weight)\n",
    "\n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        torch.nn.init.xavier_uniform_(self.linear2.weight)\n",
    "\n",
    "        self.linear3 = nn.Linear(H2, D_out)\n",
    "        torch.nn.init.xavier_uniform_(self.linear3.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.linear1(x))\n",
    "        x = torch.tanh(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "model = NetTanh_Xavier(2, 5, 5, 1)\n",
    "model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('linear1.weight',\n              tensor([[-0.5201, -0.2306],\n                      [ 0.0918,  0.4077],\n                      [-0.3124,  0.5924],\n                      [-0.5024, -0.5171],\n                      [ 0.2782,  0.6645]])),\n             ('linear1.bias',\n              tensor([ 0.5354,  0.5100,  0.0427, -0.2513, -0.5256])),\n             ('linear2.weight',\n              tensor([[-0.3190,  0.1387, -0.0316, -0.0711, -0.0853],\n                      [-0.0009, -0.2620, -0.1015,  0.3669, -0.2376],\n                      [-0.0332, -0.3532, -0.1792,  0.1515,  0.1936],\n                      [-0.3707,  0.3401,  0.1042,  0.2141, -0.2594],\n                      [ 0.3073, -0.4073, -0.3445,  0.3010, -0.1397]])),\n             ('linear2.bias',\n              tensor([ 0.1901,  0.2177, -0.1890, -0.2742,  0.2485])),\n             ('linear3.weight',\n              tensor([[ 0.2984, -0.0030,  0.0701,  0.1773,  0.1449]])),\n             ('linear3.bias', tensor([0.4170]))])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### He initialization ###\n",
    "class NetReLu_He(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        super(NetReLu_He, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        torch.nn.init.kaiming_uniform_(self.linear1.weight, nonlinearity=\"relu\")\n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        torch.nn.init.kaiming_uniform_(self.linear2.weight, nonlinearity=\"relu\")\n",
    "        self.linear3 = nn.Linear(H2, D_out)\n",
    "        torch.nn.init.kaiming_uniform_(self.linear3.weight, nonlinearity=\"relu\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        x = torch.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "model = NetReLu(2, 5, 5, 1)\n",
    "model.state_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "### momentum ###\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        self.linear3 = nn.Linear(H2, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.linear1(x))\n",
    "        x = torch.sigmoid(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "model = Net(25, 50, 50, 10)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "Net(\n  (linear1): Linear(in_features=25, out_features=50, bias=True)\n  (linear2): Linear(in_features=50, out_features=50, bias=True)\n  (linear3): Linear(in_features=50, out_features=10, bias=True)\n)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### batch normalization ###\n",
    "class Net_BatchNorm(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        super(Net_BatchNorm, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        self.linear3 = nn.Linear(H2, D_out)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(H1)\n",
    "        self.bn2 = nn.BatchNorm1d(H2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.bn1(self.linear1(x)))\n",
    "        x = F.sigmoid(self.bn2(self.linear2(x)))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "model = Net(25, 50, 50, 10)\n",
    "model.train()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}